# EmberCortex - Embedding Server Configuration
# This file is sourced by the systemd service
# After editing, restart: sudo systemctl restart embed-server

# llama.cpp build directory
LLAMA_CPP_DIR=/home/anelson/ggml-org/llama.cpp/build-cuda

# Embedding model path (GGUF format)
MODEL_PATH=/home/anelson/llm_models/nomic-embed-text-v1.5.Q8_0.gguf

# Server settings
HOST=0.0.0.0
PORT=8081

# GPU settings
GPU_LAYERS=99

# Context length for embeddings
CONTEXT_LENGTH=8192

# Batch size (must be >= max tokens per chunk)
BATCH_SIZE=8192
